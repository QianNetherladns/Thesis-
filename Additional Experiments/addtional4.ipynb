{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import subprocess\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.metrics import auc, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of each label_sentiment:\n",
      "sentiment\n",
      "Negative    262\n",
      "Neither      98\n",
      "Positive     48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions of each label_sentiment:\n",
      "sentiment\n",
      "Negative    0.642157\n",
      "Neither     0.240196\n",
      "Positive    0.117647\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('/Users/rachael/Downloads/train_df_labelled.xlsx')\n",
    "file =  data[['content','sentiment','stance']]\n",
    "file['sentiment'].value_counts()\n",
    "label_sentiment= file['sentiment'].value_counts()\n",
    "label_proportions_sentiment= file['sentiment'].value_counts(normalize=True)\n",
    "print(\"Counts of each label_sentiment:\")\n",
    "print(label_sentiment)\n",
    "print(\"\\nProportions of each label_sentiment:\")\n",
    "print(label_proportions_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Om het nog bondiger te zeggen: ik stemde ooit ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Volgens de peilingen stond PVV 2 weken geleden...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PVV stemmers mogen dan het geheugen hebben van...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Aganist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PVV wil geen vluchtelingen, Omtzigt wil geen e...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dat weten we niet. PVV heeft veel strategische...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Aganist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Ik heb vvd gestemd omdat ik een coalitie over ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Aganist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Exact, wordt niet bien van het krakeel en het ...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>De hysterische gedoe van nu kan wel later voor...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Aganist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Als je het enkel hebt over de persoon van der ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Zoek het hoefijzermodel eens op, dan zie je da...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content sentiment   stance\n",
       "0    Om het nog bondiger te zeggen: ik stemde ooit ...  Negative  Support\n",
       "1    Volgens de peilingen stond PVV 2 weken geleden...  Negative  Neither\n",
       "2    PVV stemmers mogen dan het geheugen hebben van...  Negative  Aganist\n",
       "3    PVV wil geen vluchtelingen, Omtzigt wil geen e...   Neither  Neither\n",
       "4    Dat weten we niet. PVV heeft veel strategische...   Neither  Aganist\n",
       "..                                                 ...       ...      ...\n",
       "403  Ik heb vvd gestemd omdat ik een coalitie over ...  Negative  Aganist\n",
       "404  Exact, wordt niet bien van het krakeel en het ...   Neither  Support\n",
       "405  De hysterische gedoe van nu kan wel later voor...  Negative  Aganist\n",
       "406  Als je het enkel hebt over de persoon van der ...  Positive  Neither\n",
       "407  Zoek het hoefijzermodel eens op, dan zie je da...   Neither  Neither\n",
       "\n",
       "[408 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_urls(text):\n",
    "    # 定义URL的正则表达式\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    # 使用re.sub()函数替换URL为空字符串\n",
    "    no_url_text = re.sub(url_pattern, '', text)\n",
    "    return no_url_text\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove anything that is not a letter or space\n",
    "    clean_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Optional: Convert text to lower case\n",
    "    clean_text = clean_text.lower()\n",
    "    return clean_text\n",
    "\n",
    "#remove stopwords\n",
    "def remove_stopwords(text, stopwords):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "dutch_stopwords = ['de', 'en', 'van', 'ik', 'te', 'dat', \n",
    "                  'die', 'in', 'een', 'hij', 'het', 'niet', \n",
    "                  'zijn', 'is', 'was', 'op', 'aan', 'met', 'als', \n",
    "                  'voor', 'had', 'er', 'maar', 'om', 'hem', 'dan', \n",
    "                  'zou', 'of', 'wat', 'mijn', 'men', 'dit', 'zo', \n",
    "                  'door', 'over', 'ze', 'zich', 'bij', 'ook', 'tot', \n",
    "                  'je', 'mij', 'uit', 'der', 'daar', 'haar', 'naar', \n",
    "                  'heb', 'hoe', 'heeft', 'hebben', 'deze', 'u', 'want', \n",
    "                  'nog', 'zal', 'me', 'zij', 'nu', 'ge', 'geen', 'omdat', \n",
    "                  'iets', 'worden', 'toch', 'al', 'waren', 'veel', 'meer', \n",
    "                  'doen', 'toen', 'moet', 'ben', 'zonder', 'kan', 'hun', \n",
    "                  'dus', 'alles', 'onder', 'ja', 'eens', 'hier', 'wie', \n",
    "                  'werd', 'altijd', 'doch', 'wordt', 'wezen', 'kunnen', \n",
    "                  'ons', 'zelf', 'tegen', 'na', 'reeds', 'wil', 'kon', \n",
    "                  'niets', 'uw', 'iemand', 'geweest', 'andere']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/5p2k6x290wzfc5dzz5xm78bm0000gp/T/ipykernel_17555/398425533.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  file['content'] = file['content'].apply(remove_urls)\n",
      "/var/folders/vq/5p2k6x290wzfc5dzz5xm78bm0000gp/T/ipykernel_17555/398425533.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  file['content'] = file['content'].apply(clean_text)\n",
      "/var/folders/vq/5p2k6x290wzfc5dzz5xm78bm0000gp/T/ipykernel_17555/398425533.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  file['content'] = file['content'].apply(lambda x: remove_stopwords(x, dutch_stopwords))\n",
      "/var/folders/vq/5p2k6x290wzfc5dzz5xm78bm0000gp/T/ipykernel_17555/398425533.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  file['sentiment'] = file['sentiment'].replace({'Positive':0,'Negative': 1, 'Neither': 2})\n",
      "/var/folders/vq/5p2k6x290wzfc5dzz5xm78bm0000gp/T/ipykernel_17555/398425533.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  file['stance'] = file['stance'].replace({'Support':0,'Aganist': 1, 'Neither': 2})\n"
     ]
    }
   ],
   "source": [
    "file['content'] = file['content'].apply(remove_urls) \n",
    "file['content'] = file['content'].apply(clean_text) \n",
    "file['content'] = file['content'].apply(lambda x: remove_stopwords(x, dutch_stopwords))\n",
    "file['sentiment'] = file['sentiment'].replace({'Positive':0,'Negative': 1, 'Neither': 2})\n",
    "file['stance'] = file['stance'].replace({'Support':0,'Aganist': 1, 'Neither': 2})\n",
    "y = file['sentiment']\n",
    "X = file[['content','stance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bondiger zeggen stemde ooit links ging wijken ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volgens peilingen stond pvv weken geleden zete...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pvv stemmers mogen geheugen goudvis daarnaast ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pvv vluchtelingen omtzigt expats vvd eigenlijk...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weten we pvv strategische stemmen gekregen wee...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>vvd gestemd coalitie rechts perse fan wilders ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>exact bien krakeel meehuilen wolven linkse bub...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>hysterische gedoe wel later zorgen pvv ooit ze...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>enkel hebt persoon plas toegankelijk althans v...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>zoek hoefijzermodel zie sp pvv dichter elkaar ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  sentiment  stance\n",
       "0    bondiger zeggen stemde ooit links ging wijken ...          1     0.0\n",
       "1    volgens peilingen stond pvv weken geleden zete...          1     NaN\n",
       "2    pvv stemmers mogen geheugen goudvis daarnaast ...          1     1.0\n",
       "3    pvv vluchtelingen omtzigt expats vvd eigenlijk...          2     NaN\n",
       "4    weten we pvv strategische stemmen gekregen wee...          2     NaN\n",
       "..                                                 ...        ...     ...\n",
       "404  vvd gestemd coalitie rechts perse fan wilders ...          1     1.0\n",
       "405  exact bien krakeel meehuilen wolven linkse bub...          2     NaN\n",
       "406  hysterische gedoe wel later zorgen pvv ooit ze...          1     1.0\n",
       "407  enkel hebt persoon plas toegankelijk althans v...          0     2.0\n",
       "408  zoek hoefijzermodel zie sp pvv dichter elkaar ...          2     2.0\n",
       "\n",
       "[409 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "#hyperparameter range\n",
    "param_dist = {\n",
    "    'C': np.logspace(-4, 4, 20),  # Inverse of regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'saga'],  # Solvers that support multinomial loss\n",
    "    'max_iter': [20000, 30000,40000],  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "test_scores = []\n",
    "best_params_list = []\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rachael/Desktop/data/addtional4.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachael/Desktop/data/addtional4.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m randomized_search \u001b[39m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachael/Desktop/data/addtional4.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     estimator\u001b[39m=\u001b[39mlr,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachael/Desktop/data/addtional4.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     param_distributions\u001b[39m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachael/Desktop/data/addtional4.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachael/Desktop/data/addtional4.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachael/Desktop/data/addtional4.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# 拟合随机搜索\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rachael/Desktop/data/addtional4.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m randomized_search\u001b[39m.\u001b[39;49mfit(X_train_with_stance, trainy)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachael/Desktop/data/addtional4.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# 获取最佳模型\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachael/Desktop/data/addtional4.ipynb#W5sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m best_model \u001b[39m=\u001b[39m randomized_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1810\u001b[0m         ParameterSampler(\n\u001b[1;32m   1811\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1812\u001b[0m         )\n\u001b[1;32m   1813\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 分层K折交叉验证\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "test_scores = []\n",
    "best_params_list = []\n",
    "\n",
    "# 循环每个折叠\n",
    "for train_index, test_index in outer_cv.split(X, y):\n",
    "    trainX, testX = X.iloc[train_index], X.iloc[test_index]\n",
    "    trainy, testy = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # 使用TF-IDF变换训练数据\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(trainX['content'])\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(testX['content'])\n",
    "    \n",
    "    # 将stance特征转换为二维数组后再进行堆叠\n",
    "    X_train_with_stance = np.hstack([X_train_tfidf.toarray(), trainX['stance'].values.reshape(-1, 1)])\n",
    "    X_test_with_stance = np.hstack([X_test_tfidf.toarray(), testX['stance'].values.reshape(-1, 1)])\n",
    "\n",
    "    lr = LogisticRegression(multi_class='multinomial', random_state=42, class_weight='balanced')\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=lr,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=100,  # Number of parameter settings that are sampled\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        cv=inner_cv,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "  \n",
    "    # 拟合随机搜索\n",
    "    randomized_search.fit(X_train_with_stance, trainy)\n",
    "\n",
    "    # 获取最佳模型\n",
    "    best_model = randomized_search.best_estimator_\n",
    "    best_params = randomized_search.best_params_\n",
    "    best_score = randomized_search.best_score_\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    test_predictions = best_model.predict(X_test_with_stance)\n",
    "    test_score = f1_score(testy, test_predictions, average='macro')\n",
    "\n",
    "    # 存储结果\n",
    "    test_scores.append(test_score)\n",
    "    best_params_list.append(best_params)\n",
    "\n",
    "    print(f\"Fold test score: {test_score}\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# 汇总结果\n",
    "mean_test_score = np.mean(test_scores)\n",
    "std_test_score = np.std(test_scores)\n",
    "\n",
    "print(f\"Mean test score: {mean_test_score}\")\n",
    "print(f\"Standard deviation of test scores: {std_test_score}\")\n",
    "print(\"Best parameters for each fold:\")\n",
    "for i, params in enumerate(best_params_list):\n",
    "    print(f\"Fold {i + 1}: {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
